services:
  postgres:
    image: postgres:16-alpine
    container_name: ai-studio-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=lifeos
      - POSTGRES_USER=lifeos
      - POSTGRES_PASSWORD=lifeos_dev_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lifeos"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: ai-studio-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ai-studio-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    # Resource limits for Ollama (256GB unified memory system)
    deploy:
      resources:
        limits:
          cpus: '16.0'
          memory: 200G  # Increased for 120B models (256GB system)
        reservations:
          cpus: '8.0'
          memory: 100G

  api:
    build: .
    container_name: ai-studio-api
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      # Docker environment flag
      - DOCKER_ENV=1
      # Database configuration
      - DATABASE_URL=postgresql+asyncpg://lifeos:lifeos_dev_password@postgres:5432/lifeos
      # Redis configuration
      - REDIS_URL=redis://redis:6379/0
      - JOB_STORAGE_BACKEND=redis
      # API Configuration
      - API_TITLE=AI-Studio API
      - API_VERSION=1.0.0
      - HOST=0.0.0.0
      - PORT=8000
      # Authentication (set JWT_SECRET_KEY in .env for production!)
      - REQUIRE_AUTH=true
      # - JWT_SECRET_KEY=your-secret-key-here  # Set this in .env!
      # Ollama configuration
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_API_BASE=http://ollama:11434  # LiteLLM uses this variable

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy

    volumes:
      # Persistent volumes
      - ./presets:/app/presets           # Preset storage (persistent)
      - ./output:/app/output             # Generated images (persistent)
      - ./logs:/app/logs                 # Application logs (persistent)
      - ./data:/app/data                 # User accounts and persistent data

      # Optional volumes
      - ./cache:/app/cache               # Cache (can be ephemeral)
      - ./uploads:/app/uploads           # Temporary uploads
      - ./subjects:/app/subjects         # Subject images for composition

      # Mount configs (read-only)
      - ./configs:/app/configs:ro

      # Development volumes (for testing and live code updates)
      - ./api:/app/api                   # API source code
      - ./ai_tools:/app/ai_tools         # AI tools source code
      - ./ai_capabilities:/app/ai_capabilities  # Specs and schemas
      - ./tests:/app/tests               # Test files

    restart: unless-stopped

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    # Resource limits (adjusted for batch operations - 256GB system)
    deploy:
      resources:
        limits:
          cpus: '8.0'
          memory: 16G
        reservations:
          cpus: '2.0'
          memory: 4G

  rq-worker:
    build: .
    # Removed container_name to allow scaling (docker-compose up --scale rq-worker=N)
    command: rq worker --url redis://redis:6379/0 --worker-class rq.Worker normal high low
    env_file:
      - .env
    environment:
      # Docker environment flag
      - DOCKER_ENV=1
      # Database configuration
      - DATABASE_URL=postgresql+asyncpg://lifeos:lifeos_dev_password@postgres:5432/lifeos
      # Redis configuration
      - REDIS_URL=redis://redis:6379/0
      # Ollama configuration
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_API_BASE=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      # Same volumes as API for access to data and tools
      - ./presets:/app/presets
      - ./output:/app/output
      - ./logs:/app/logs
      - ./data:/app/data
      - ./cache:/app/cache
      - ./uploads:/app/uploads
      - ./subjects:/app/subjects
      - ./configs:/app/configs:ro
      - ./api:/app/api
      - ./ai_tools:/app/ai_tools
      - ./ai_capabilities:/app/ai_capabilities
    restart: unless-stopped
    # Resource limits for workers
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 2G

  frontend:
    build: ./frontend
    container_name: ai-studio-frontend
    ports:
      - "3000:80"
    depends_on:
      - api
    restart: unless-stopped

# Optional: Add volumes for named volumes instead of bind mounts
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_models:
    driver: local
  presets:
    driver: local
  output:
    driver: local
  cache:
    driver: local
