#!/bin/bash
#
# Cloud Upload Script Template
# Uploads backups to cloud storage (Backblaze B2, AWS S3, Google Cloud)
#
# SETUP INSTRUCTIONS:
# 1. Choose your cloud provider (uncomment relevant section)
# 2. Install CLI tool (see instructions below)
# 3. Configure credentials
# 4. Copy this file to upload_to_cloud.sh
# 5. Make executable: chmod +x upload_to_cloud.sh
# 6. Test: ./upload_to_cloud.sh
#
# Usage: ./upload_to_cloud.sh

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
BACKUP_DIR="$PROJECT_DIR/backups"

# ========================================
# OPTION 1: BACKBLAZE B2 (RECOMMENDED)
# ========================================
# Cost: ~$2/month for 100GB
# Install: brew install b2-tools
# Setup: https://www.backblaze.com/b2/cloud-storage.html

B2_BUCKET="life-os-backups"
B2_KEY_ID="${B2_APPLICATION_KEY_ID:-}"
B2_APP_KEY="${B2_APPLICATION_KEY:-}"

# ========================================
# OPTION 2: AWS S3
# ========================================
# Cost: ~$2.30/month for 100GB (S3 Standard)
# Install: brew install awscli
# Setup: aws configure

# S3_BUCKET="s3://life-os-backups"
# AWS_PROFILE="default"  # or your profile name

# ========================================
# OPTION 3: GOOGLE CLOUD STORAGE
# ========================================
# Cost: ~$2/month for 100GB (Standard Storage)
# Install: brew install google-cloud-sdk
# Setup: gcloud auth login

# GCS_BUCKET="gs://life-os-backups"
# GCP_PROJECT="your-project-id"

# ========================================
# OPTION 4: AZURE BLOB STORAGE
# ========================================
# Cost: ~$2.20/month for 100GB (Hot tier)
# Install: brew install azure-cli
# Setup: az login

# AZURE_CONTAINER="life-os-backups"
# AZURE_ACCOUNT="your-storage-account"

# ========================================
# END CONFIGURATION
# ========================================

echo "â˜ï¸  Uploading backups to cloud storage..."
echo ""

# ========================================
# BACKBLAZE B2 IMPLEMENTATION
# ========================================
upload_to_b2() {
    # Check if b2 CLI is installed
    if ! command -v b2 &> /dev/null; then
        echo "âš ï¸  Backblaze B2 CLI not installed"
        echo "   Install: brew install b2-tools"
        exit 1
    fi

    # Check credentials
    if [ -z "$B2_KEY_ID" ] || [ -z "$B2_APP_KEY" ]; then
        echo "âš ï¸  B2 credentials not set"
        echo "   Set environment variables:"
        echo "     export B2_APPLICATION_KEY_ID='your-key-id'"
        echo "     export B2_APPLICATION_KEY='your-app-key'"
        exit 1
    fi

    # Authenticate
    echo "Authenticating with Backblaze B2..."
    b2 authorize-account "$B2_KEY_ID" "$B2_APP_KEY" > /dev/null
    echo "âœ“ Authenticated"
    echo ""

    # Upload latest PostgreSQL backup
    LATEST_POSTGRES=$(ls -t "$BACKUP_DIR/postgres"/*.sql.gz 2>/dev/null | head -1)
    if [ -n "$LATEST_POSTGRES" ]; then
        echo "ðŸ“¤ Uploading PostgreSQL backup..."
        echo "   File: $(basename "$LATEST_POSTGRES")"
        PG_SIZE=$(du -sh "$LATEST_POSTGRES" | cut -f1)
        echo "   Size: $PG_SIZE"
        b2 upload-file "$B2_BUCKET" "$LATEST_POSTGRES" "postgres/$(basename "$LATEST_POSTGRES")"
        echo "   âœ“ Uploaded"
    fi
    echo ""

    # Upload latest application data backup
    LATEST_APP_DATA=$(ls -t "$BACKUP_DIR/app_data"/*.tar.gz 2>/dev/null | head -1)
    if [ -n "$LATEST_APP_DATA" ]; then
        echo "ðŸ“¤ Uploading application data backup..."
        echo "   File: $(basename "$LATEST_APP_DATA")"
        APP_SIZE=$(du -sh "$LATEST_APP_DATA" | cut -f1)
        echo "   Size: $APP_SIZE"
        b2 upload-file "$B2_BUCKET" "$LATEST_APP_DATA" "app_data/$(basename "$LATEST_APP_DATA")"
        echo "   âœ“ Uploaded"
    fi
    echo ""

    # Upload Ollama models monthly (optional - 122GB)
    if [ "$(date +%d)" -eq 1 ]; then
        LATEST_OLLAMA=$(ls -t "$BACKUP_DIR/docker_volumes"/ollama_models_*.tar.gz 2>/dev/null | head -1)
        if [ -n "$LATEST_OLLAMA" ]; then
            echo "ðŸ“¤ Uploading Ollama models (monthly - this will take a while)..."
            echo "   File: $(basename "$LATEST_OLLAMA")"
            OLLAMA_SIZE=$(du -sh "$LATEST_OLLAMA" | cut -f1)
            echo "   Size: $OLLAMA_SIZE"
            echo "   âš ï¸  This may take 30-60 minutes over home internet"
            b2 upload-file --threads 4 "$B2_BUCKET" "$LATEST_OLLAMA" "ollama/$(basename "$LATEST_OLLAMA")"
            echo "   âœ“ Uploaded"
        fi
    fi

    # List remote files
    echo "ðŸ“‹ Remote backup files:"
    b2 ls "$B2_BUCKET" --recursive | tail -10
    echo ""
}

# ========================================
# AWS S3 IMPLEMENTATION (ALTERNATIVE)
# ========================================
upload_to_s3() {
    if ! command -v aws &> /dev/null; then
        echo "âš ï¸  AWS CLI not installed"
        echo "   Install: brew install awscli"
        exit 1
    fi

    echo "Uploading to AWS S3: $S3_BUCKET"

    # Upload latest backups
    LATEST_POSTGRES=$(ls -t "$BACKUP_DIR/postgres"/*.sql.gz 2>/dev/null | head -1)
    if [ -n "$LATEST_POSTGRES" ]; then
        echo "ðŸ“¤ Uploading PostgreSQL backup..."
        aws s3 cp "$LATEST_POSTGRES" "$S3_BUCKET/postgres/"
    fi

    LATEST_APP_DATA=$(ls -t "$BACKUP_DIR/app_data"/*.tar.gz 2>/dev/null | head -1)
    if [ -n "$LATEST_APP_DATA" ]; then
        echo "ðŸ“¤ Uploading application data..."
        aws s3 cp "$LATEST_APP_DATA" "$S3_BUCKET/app_data/"
    fi

    # List remote files
    echo "ðŸ“‹ Remote backup files:"
    aws s3 ls "$S3_BUCKET/" --recursive | tail -10
}

# ========================================
# MAIN EXECUTION
# ========================================

# Uncomment the provider you're using:
upload_to_b2           # Backblaze B2
# upload_to_s3         # AWS S3
# upload_to_gcs        # Google Cloud
# upload_to_azure      # Azure Blob

echo "========================================="
echo "âœ… Cloud upload complete"
echo "========================================="
