# AI-Studio Model Configuration
#
# This file defines which models are used for each tool by default.
# Models can be overridden per-run using command-line flags.

# Default models for each tool
defaults:
  # Image Analysis Tools
  outfit_analyzer: "gemini/gemini-2.0-flash-exp"
  visual_style_analyzer: "gemini/gemini-2.0-flash-exp"
  art_style_analyzer: "gemini/gemini-2.0-flash-exp"
  hair_style_analyzer: "gemini/gemini-2.0-flash-exp"
  hair_color_analyzer: "gemini/gemini-2.0-flash-exp"
  makeup_analyzer: "gemini/gemini-2.0-flash-exp"
  expression_analyzer: "gemini/gemini-2.0-flash-exp"
  accessories_analyzer: "gemini/gemini-2.0-flash-exp"
  comprehensive_analyzer: "gemini/gemini-2.0-flash-exp"
  style_guide_analyzer: "gemini/gemini-2.0-flash-exp"
  character_appearance_analyzer: "ollama/gpt-oss:120b"  # Local 120B model (FREE!)

  # Entity Management Tools
  entity_merger: "gemini/gemini-2.0-flash-exp"  # Fast model for merging entities
  clothing_modifier: "gemini/gemini-2.0-flash-exp"  # Modify clothing descriptions with AI

  # Image Generation Tools
  # NOTE: If COMFYUI_ENABLED=true, these will auto-route to local ComfyUI ($0 cost)
  # Otherwise they use cloud providers (Gemini ~$0.04/image)
  outfit_generator: "comfyui/qwen-edit"  # Local Qwen for outfit transformations (FREE!)
  style_transfer_generator: "comfyui/qwen-edit"  # Local Qwen for style transfers (FREE!)
  modular_image_generator: "comfyui/qwen-edit"  # Local Qwen for modular generation (FREE!)
  art_style_generator: "comfyui/qwen-edit"  # Local Qwen for art style application (FREE!)
  style_guide_generator: "comfyui/qwen-edit"  # Local Qwen for style guide viz (FREE!)
  combined_transformation: "comfyui/qwen-edit"  # Local Qwen for combined transforms (FREE!)

  # Video Tools
  video_prompt_enhancer: "gpt-4o"
  sora_video_generator: "sora-2-pro"

  # General defaults
  timeout: 180
  retries: 3
  temperature: 0.7

# Environment-specific overrides
overrides:
  development:
    # Use faster/cheaper models in development
    outfit_analyzer: "gemini-1.5-flash"
    visual_style_analyzer: "gemini-1.5-flash"
    art_style_analyzer: "gemini-1.5-flash"
    video_prompt_enhancer: "gpt-4o-mini"
    sora_video_generator: "sora-2"

  production:
    # Use best models in production
    video_prompt_enhancer: "gpt-5"
    sora_video_generator: "sora-2-pro"

  experimental:
    # Try experimental models
    outfit_analyzer: "gemini-2.0-flash-exp"
    video_prompt_enhancer: "gpt-5"

# LiteLLM routing configuration
routing:
  # Timeout for API calls (seconds)
  timeout: 180

  # Number of retries on failure
  retries: 3

  # Fallback models if primary fails
  fallback_models:
    - "gemini/gemini-2.0-flash-exp"
    - "claude-3-5-sonnet"
    - "gpt-4o"

  # Rate limiting (requests per second)
  rate_limit:
    gemini: 2.0
    openai: 2.0
    anthropic: 2.0

# Model aliases (for convenience)
aliases:
  gemini: "gemini/gemini-2.0-flash-exp"
  gpt: "gpt-4o"
  claude: "claude-3-5-sonnet"
  sora: "sora-2-pro"
  # Local models via Ollama (prefix with "ollama/")
  llama: "ollama/llama3.2:3b"
  mistral: "ollama/mistral:7b"
  qwen: "ollama/qwen2.5:7b"
  codellama: "ollama/codellama:7b"

# Cost tracking (approximate USD per 1M tokens)
cost_estimates:
  input:
    gemini-2.0-flash: 0.15
    gemini-1.5-flash: 0.075
    gpt-4o: 2.50
    gpt-4o-mini: 0.15
    claude-3-5-sonnet: 3.00
  output:
    gemini-2.0-flash: 0.60
    gemini-1.5-flash: 0.30
    gpt-4o: 10.00
    gpt-4o-mini: 0.60
    claude-3-5-sonnet: 15.00

# Image generation costs (per image)
image_costs:
  # Cloud providers
  gemini-2.5-flash-image: 0.04  # Gemini dedicated image generation model
  dall-e-3: 0.04
  dall-e-2: 0.02
  # Local ComfyUI (FREE!)
  comfyui/qwen-edit: 0.00  # Local Qwen image editing
  comfyui/ip-adapter: 0.00  # Local SDXL + IP-Adapter
  comfyui/sdxl: 0.00  # Local SDXL text-to-image

# Video generation costs (per second)
video_costs:
  sora-2: 0.125
  sora-2-pro: 0.50

# Local models configuration
local_models:
  # Recommended models by size (download with: POST /local-models/pull)
  small:  # 2-4GB, fast inference
    - "llama3.2:3b"      # 3B params, ~2GB, good for testing
    - "phi3:mini"        # 3.8B params, ~2.3GB, fast
    - "gemma2:2b"        # 2B params, ~1.6GB, very fast

  medium:  # 4-8GB, balanced performance
    - "llama2:7b"        # 7B params, ~4GB, reliable
    - "mistral:7b"       # 7B params, ~4GB, fast inference
    - "qwen2.5:7b"       # 7B params, ~4.7GB, strong performance
    - "codellama:7b"     # 7B params, ~4GB, code generation

  large:  # 26-50GB, powerful but slow
    - "mixtral:8x7b"     # 47B params, ~26GB, very powerful
    - "qwen2.5:32b"      # 32B params, ~19GB, strong reasoning
    - "llama3.1:70b"     # 70B params, ~40GB, very strong

  xlarge:  # 40GB+, requires significant resources
    - "qwen2.5:72b"      # 72B params, ~41GB, similar to GPT-4 class
    - "llama3.1:405b"    # 405B params, ~231GB, cutting-edge (requires multiple GPUs)

  # Cost per 1M tokens (all FREE for local models!)
  cost:
    input: 0.0
    output: 0.0

# Tool-specific settings (temperature, etc.)
tool_settings:
  character_appearance_analyzer:
    temperature: 0.3

# ComfyUI Local Image Generation Configuration
# Set COMFYUI_ENABLED=true in .env to enable local generation (saves $0.04/image!)
comfyui:
  # Enable/disable ComfyUI routing
  enabled: true  # Controlled by COMFYUI_ENABLED env var

  # Fallback to cloud if ComfyUI unavailable
  fallback_to_cloud: true  # Set COMFYUI_FALLBACK_TO_CLOUD=false to disable

  # ComfyUI server URL
  url: "http://localhost:8188"  # Set COMFYUI_URL to override

  # Request timeout (seconds)
  timeout: 300

  # Workflow-specific parameters
  workflows:
    qwen_edit:
      steps: 4  # 4-step Lightning LoRA for fast generation
      cfg: 1.0  # CFG scale (1.0 recommended for Lightning)
      denoise: 1.0  # Denoise strength (1.0 = full denoise)

    qwen_edit_gguf:
      steps: 4
      cfg: 1.0
      denoise: 1.0
      # GGUF models use less VRAM but slightly lower quality

    sdxl_text2img:
      width: 1024
      height: 1024
      steps: 20
      cfg: 7.0
      checkpoint: "sd_xl_base_1.0.safetensors"

    sdxl_ipadapter:
      width: 1024
      height: 1024
      steps: 20
      cfg: 7.0
      ipadapter_weight: 1.0  # IP-Adapter strength (0.0-1.0)
      checkpoint: "sd_xl_base_1.0.safetensors"
      ipadapter_model: "ip-adapter_sdxl_vit-h.safetensors"
