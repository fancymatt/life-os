# Available Models Registry
# This file defines all models available in the system.
# Models are organized by provider and only shown in the UI if the corresponding API key is configured.

providers:
  gemini:
    env_var: GEMINI_API_KEY
    models:
      - id: gemini/gemini-2.0-flash-exp
        name: Gemini 2.0 Flash (Experimental)
        supports: [text, image_analysis, structured_output]

      - id: gemini/gemini-1.5-flash
        name: Gemini 1.5 Flash
        supports: [text, image_analysis, structured_output]

      - id: gemini/gemini-1.5-pro
        name: Gemini 1.5 Pro
        supports: [text, image_analysis, structured_output]

      - id: gemini/gemini-2.5-flash-image
        name: Gemini 2.5 Flash Image
        supports: [image_generation]

  openai:
    env_var: OPENAI_API_KEY
    models:
      - id: gpt-4o
        name: GPT-4o
        supports: [text, image_analysis, structured_output]

      - id: gpt-4o-mini
        name: GPT-4o Mini
        supports: [text, image_analysis, structured_output]

      - id: gpt-5
        name: GPT-5
        supports: [text, image_analysis, structured_output]
        temperature_restrictions:
          fixed: 1.0
          note: "GPT-5 only supports temperature=1.0"

      - id: dall-e-3
        name: DALL-E 3
        supports: [image_generation]

  anthropic:
    env_var: ANTHROPIC_API_KEY
    models:
      - id: claude-3-5-sonnet-20241022
        name: Claude 3.5 Sonnet
        supports: [text, image_analysis, structured_output]

      - id: claude-3-opus-20240229
        name: Claude 3 Opus
        supports: [text, structured_output]

  # Local LLM provider via Ollama (FREE!)
  ollama:
    env_var: OLLAMA_BASE_URL  # Local service, no API key needed
    models:
      # Small models (2-4GB) - Fast inference
      - id: ollama/llama3.2:3b
        name: Llama 3.2 3B (Local)
        supports: [text, image_analysis, structured_output]

      - id: ollama/phi3:mini
        name: Phi 3 Mini (Local)
        supports: [text, structured_output]

      - id: ollama/gemma2:2b
        name: Gemma 2 2B (Local)
        supports: [text, structured_output]

      # Medium models (4-8GB) - Balanced performance
      - id: ollama/llama2:7b
        name: Llama 2 7B (Local)
        supports: [text, structured_output]

      - id: ollama/mistral:7b
        name: Mistral 7B (Local)
        supports: [text, structured_output]

      - id: ollama/qwen2.5:7b
        name: Qwen 2.5 7B (Local)
        supports: [text, structured_output]

      - id: ollama/codellama:7b
        name: Code Llama 7B (Local)
        supports: [text, structured_output]

      # Vision models (7-13GB) - Image understanding
      - id: ollama/llama3.2-vision:11b
        name: Llama 3.2 Vision 11B (Local) üëÅÔ∏è
        supports: [text, image_analysis, structured_output]

      - id: ollama/llava:13b
        name: LLaVA 13B (Local) üëÅÔ∏è
        supports: [text, image_analysis, structured_output]

      # Large models (26-50GB) - Powerful but slow
      - id: ollama/mixtral:8x7b
        name: Mixtral 8x7B (Local)
        supports: [text, structured_output]

      - id: ollama/qwen2.5:32b
        name: Qwen 2.5 32B (Local)
        supports: [text, structured_output]

      - id: ollama/llama3.1:70b
        name: Llama 3.1 70B (Local)
        supports: [text, image_analysis, structured_output]

      # XLarge models (40GB+) - Best quality
      - id: ollama/qwen2.5:72b
        name: Qwen 2.5 72B (Local)
        supports: [text, image_analysis, structured_output]

      - id: ollama/gpt-oss:120b
        name: GPT-OSS 120B (Local) ‚ö°
        supports: [text, image_analysis, structured_output]

      - id: ollama/llama3.1:405b
        name: Llama 3.1 405B (Local)
        supports: [text, image_analysis, structured_output]

  # Future providers (commented out until implemented)
  # openai-video:
  #   env_var: OPENAI_API_KEY  # Requires special access
  #   models:
  #     - id: sora-2
  #       name: Sora 2
  #       supports: [video_generation]
